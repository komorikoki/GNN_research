{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3448feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training data: 104664\n",
      "num validation data: 13083\n",
      "num test data: 13084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Linear\n",
    "\n",
    "\n",
    "dataset = QM9(root='./data/QM9')\n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_idx, temp_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = dataset[train_idx]\n",
    "val_dataset = dataset[val_idx]\n",
    "test_dataset = dataset[test_idx]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "TARGET_INDEX = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_node_features = dataset.num_node_features\n",
    "hidden_channels = 64\n",
    "EPOCHS = 15 \n",
    "criterion = torch.nn.L1Loss() \n",
    "\n",
    "print(f\"num training data: {len(train_dataset)}\")\n",
    "print(f\"num validation data: {len(val_dataset)}\")\n",
    "print(f\"num test data: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97b880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "LOG_DIR = 'runs'\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def evaluate(loader, model):\n",
    "    model.eval()\n",
    "    total_error = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            target = data.y[:, TARGET_INDEX].unsqueeze(1)\n",
    "            out = model(data)\n",
    "            \n",
    "            loss = criterion(out, target) \n",
    "            total_error += loss.item() * data.num_graphs\n",
    "    return total_error / len(loader.dataset)\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, name):\n",
    "    print(f\"\\n===== train start: {name} =====\")\n",
    "    model.to(device)\n",
    "    best_val_mae = float('inf')\n",
    "    \n",
    "    writer = SummaryWriter(os.path.join(LOG_DIR, name))\n",
    "    \n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'{name}_best.pt')\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            target = data.y[:, TARGET_INDEX].unsqueeze(1)\n",
    "            out = model(data)\n",
    "            \n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            \n",
    "        train_mae = total_loss / len(train_loader.dataset)\n",
    "        val_mae = evaluate(val_loader, model)\n",
    "        \n",
    "        writer.add_scalar('MAE/Train', train_mae, epoch)\n",
    "        writer.add_scalar('MAE/Validation', val_mae, epoch)\n",
    "        \n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Best model saved with Val MAE: {best_val_mae:.4f}\")\n",
    "            \n",
    "        print(f'Epoch: {epoch:02d}/{EPOCHS}, Train MAE: {train_mae:.4f}, Val MAE: {val_mae:.4f} (Best: {best_val_mae:.4f})')\n",
    "        \n",
    "    writer.close()\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "    test_mae = evaluate(test_loader, model)\n",
    "    print(f\"=================================\")\n",
    "    print(f\"final results {name} MAE: {test_mae:.4f}\")\n",
    "    return test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4922f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train start: GIN =====\n",
      "Best model saved with Val MAE: 929.4878\n",
      "Epoch: 01/15, Train MAE: 2337.7697, Val MAE: 929.4878 (Best: 929.4878)\n",
      "Best model saved with Val MAE: 761.6856\n",
      "Epoch: 02/15, Train MAE: 1893.9807, Val MAE: 761.6856 (Best: 761.6856)\n",
      "Best model saved with Val MAE: 516.8287\n",
      "Epoch: 03/15, Train MAE: 1810.6599, Val MAE: 516.8287 (Best: 516.8287)\n",
      "Epoch: 04/15, Train MAE: 1781.9870, Val MAE: 613.8860 (Best: 516.8287)\n",
      "Epoch: 05/15, Train MAE: 1760.7804, Val MAE: 815.3360 (Best: 516.8287)\n",
      "Best model saved with Val MAE: 356.4003\n",
      "Epoch: 06/15, Train MAE: 1750.9598, Val MAE: 356.4003 (Best: 356.4003)\n",
      "Epoch: 07/15, Train MAE: 1756.9425, Val MAE: 364.8271 (Best: 356.4003)\n",
      "Epoch: 08/15, Train MAE: 1733.9678, Val MAE: 612.0268 (Best: 356.4003)\n",
      "Epoch: 09/15, Train MAE: 1724.8210, Val MAE: 801.6935 (Best: 356.4003)\n",
      "Epoch: 10/15, Train MAE: 1727.6436, Val MAE: 425.7948 (Best: 356.4003)\n",
      "Epoch: 11/15, Train MAE: 1723.1812, Val MAE: 474.6507 (Best: 356.4003)\n",
      "Best model saved with Val MAE: 318.9519\n",
      "Epoch: 12/15, Train MAE: 1723.9510, Val MAE: 318.9519 (Best: 318.9519)\n",
      "Epoch: 13/15, Train MAE: 1710.5258, Val MAE: 335.3410 (Best: 318.9519)\n",
      "Epoch: 14/15, Train MAE: 1702.5273, Val MAE: 434.7407 (Best: 318.9519)\n",
      "Best model saved with Val MAE: 109.2840\n",
      "Epoch: 15/15, Train MAE: 1716.8923, Val MAE: 109.2840 (Best: 109.2840)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17915/2230799113.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "final results GIN MAE: 109.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109.00427866754674"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GINConv(Linear(in_channels, hidden_channels))\n",
    "        self.conv2 = GINConv(Linear(hidden_channels, hidden_channels))\n",
    "        self.conv3 = GINConv(Linear(hidden_channels, hidden_channels))\n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1) \n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        x = global_add_pool(x, batch) \n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return self.lin2(x)\n",
    "\n",
    "model_gin = GIN(num_node_features, hidden_channels)\n",
    "optimizer_gin = torch.optim.Adam(model_gin.parameters(), lr=0.001)\n",
    "train_model(model_gin, optimizer_gin, \"GIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55855d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train start: PNA =====\n",
      "Best model saved with Val MAE: 1250.9000\n",
      "Epoch: 01/15, Train MAE: 2086.0595, Val MAE: 1250.9000 (Best: 1250.9000)\n",
      "Best model saved with Val MAE: 141.1460\n",
      "Epoch: 02/15, Train MAE: 1949.8272, Val MAE: 141.1460 (Best: 141.1460)\n",
      "Epoch: 03/15, Train MAE: 1931.2274, Val MAE: 156.9632 (Best: 141.1460)\n",
      "Epoch: 04/15, Train MAE: 1925.0297, Val MAE: 765.9513 (Best: 141.1460)\n",
      "Best model saved with Val MAE: 104.0245\n",
      "Epoch: 05/15, Train MAE: 1926.4879, Val MAE: 104.0245 (Best: 104.0245)\n",
      "Epoch: 06/15, Train MAE: 1921.8270, Val MAE: 933.1798 (Best: 104.0245)\n",
      "Epoch: 07/15, Train MAE: 1900.7774, Val MAE: 743.4008 (Best: 104.0245)\n",
      "Epoch: 08/15, Train MAE: 1916.5491, Val MAE: 315.2469 (Best: 104.0245)\n",
      "Epoch: 09/15, Train MAE: 1907.4388, Val MAE: 168.8342 (Best: 104.0245)\n",
      "Epoch: 10/15, Train MAE: 1906.4600, Val MAE: 456.7598 (Best: 104.0245)\n",
      "Epoch: 11/15, Train MAE: 1900.6672, Val MAE: 770.0054 (Best: 104.0245)\n",
      "Epoch: 12/15, Train MAE: 1903.6220, Val MAE: 874.6266 (Best: 104.0245)\n",
      "Epoch: 13/15, Train MAE: 1901.3800, Val MAE: 316.5062 (Best: 104.0245)\n",
      "Epoch: 14/15, Train MAE: 1902.7405, Val MAE: 1266.7532 (Best: 104.0245)\n",
      "Epoch: 15/15, Train MAE: 1903.8107, Val MAE: 768.2584 (Best: 104.0245)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17915/2230799113.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "final results PNA MAE: 103.3628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103.36280147980492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import PNAConv, global_add_pool\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "max_deg = -1\n",
    "for data in dataset:\n",
    "    max_deg = max(max_deg, int(degree(data.edge_index[0]).max().item()))\n",
    "\n",
    "deg = torch.zeros(max_deg + 1, dtype=torch.long)\n",
    "for data in dataset:\n",
    "    d = degree(data.edge_index[0], dtype=torch.long)\n",
    "    deg += torch.bincount(d, minlength=deg.numel())\n",
    "\n",
    "mean_deg = (deg.view(-1).float() * torch.arange(deg.numel()).float()).sum() / deg.sum()\n",
    "std_deg = torch.sqrt(((deg.view(-1).float() * (torch.arange(deg.numel()).float() - mean_deg) ** 2).sum() / deg.sum()))\n",
    "\n",
    "class PNA(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        aggregators = ['mean', 'min', 'max', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "        \n",
    "        self.conv1 = PNAConv(in_channels, hidden_channels, \n",
    "                             aggregators=aggregators, scalers=scalers, \n",
    "                             deg=deg,\n",
    "                             towers=4,\n",
    "                             divide_input=False)\n",
    "        self.conv2 = PNAConv(hidden_channels, hidden_channels, aggregators=aggregators, scalers=scalers, deg=deg)\n",
    "        self.conv3 = PNAConv(hidden_channels, hidden_channels, aggregators=aggregators, scalers=scalers, deg=deg)\n",
    "        \n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        \n",
    "        x = global_add_pool(x, batch) \n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return self.lin2(x)\n",
    "\n",
    "model_pna = PNA(num_node_features, hidden_channels)\n",
    "optimizer_pna = torch.optim.Adam(model_pna.parameters(), lr=0.001)\n",
    "train_model(model_pna, optimizer_pna, \"PNA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95ea8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== train start: GATv2 =====\n",
      "Best model saved with Val MAE: 602.0786\n",
      "Epoch: 01/15, Train MAE: 2092.1044, Val MAE: 602.0786 (Best: 602.0786)\n",
      "Epoch: 02/15, Train MAE: 1784.7776, Val MAE: 745.3424 (Best: 602.0786)\n",
      "Best model saved with Val MAE: 252.0302\n",
      "Epoch: 03/15, Train MAE: 1781.5928, Val MAE: 252.0302 (Best: 252.0302)\n",
      "Epoch: 04/15, Train MAE: 1780.2251, Val MAE: 786.3262 (Best: 252.0302)\n",
      "Epoch: 05/15, Train MAE: 1787.3259, Val MAE: 502.5818 (Best: 252.0302)\n",
      "Epoch: 06/15, Train MAE: 1781.9592, Val MAE: 327.7183 (Best: 252.0302)\n",
      "Epoch: 07/15, Train MAE: 1766.1234, Val MAE: 771.0888 (Best: 252.0302)\n",
      "Best model saved with Val MAE: 237.1533\n",
      "Epoch: 08/15, Train MAE: 1769.9386, Val MAE: 237.1533 (Best: 237.1533)\n",
      "Epoch: 09/15, Train MAE: 1776.4262, Val MAE: 390.6685 (Best: 237.1533)\n",
      "Epoch: 10/15, Train MAE: 1776.7240, Val MAE: 639.0611 (Best: 237.1533)\n",
      "Epoch: 11/15, Train MAE: 1775.0261, Val MAE: 484.4454 (Best: 237.1533)\n",
      "Epoch: 12/15, Train MAE: 1766.7540, Val MAE: 991.3251 (Best: 237.1533)\n",
      "Epoch: 13/15, Train MAE: 1771.0770, Val MAE: 509.7237 (Best: 237.1533)\n",
      "Epoch: 14/15, Train MAE: 1775.0410, Val MAE: 433.3900 (Best: 237.1533)\n",
      "Epoch: 15/15, Train MAE: 1767.5300, Val MAE: 303.7556 (Best: 237.1533)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17915/2230799113.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "final results GATv2 MAE: 237.0748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237.07477998514855"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GATv2Conv, global_add_pool\n",
    "\n",
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads) \n",
    "        self.conv2 = GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads)\n",
    "        self.conv3 = GATv2Conv(hidden_channels * heads, hidden_channels, heads=1) \n",
    "\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = F.elu(self.conv3(x, edge_index))\n",
    "        \n",
    "        x = global_add_pool(x, batch) \n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return self.lin2(x)\n",
    "\n",
    "model_gatv2 = GATv2(num_node_features, hidden_channels, heads=4)\n",
    "optimizer_gatv2 = torch.optim.Adam(model_gatv2.parameters(), lr=0.001)\n",
    "train_model(model_gatv2, optimizer_gatv2, \"GATv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16772df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "GIN モデルの総パラメータ数: 13313\n",
      "PNA モデルの総パラメータ数: 150069\n",
      "GATv2 モデルの総パラメータ数: 176001\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    PyTorchモデルの訓練可能なパラメータの総数を計算する関数\n",
    "    \"\"\"\n",
    "    # model.parameters() は訓練可能な全パラメータ (重みとバイアス) のイテレータを返す\n",
    "    # p.numel() はテンソル p が持つ要素の総数を返す\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params\n",
    "\n",
    "# 以前のステップで定義した GNN モデルのインスタンスを想定\n",
    "# (model_gin, model_pna, model_gatv2 がメモリにロードされている必要があります)\n",
    "\n",
    "print(f\"==========================================\")\n",
    "\n",
    "# GIN モデルのパラメータ数を計算\n",
    "if 'model_gin' in locals():\n",
    "    params_gin = count_parameters(model_gin)\n",
    "    print(f\"GIN モデルの総パラメータ数: {params_gin}\")\n",
    "else:\n",
    "    print(\"GIN モデルのインスタンスが見つかりません。\")\n",
    "\n",
    "# PNA モデルのパラメータ数を計算\n",
    "if 'model_pna' in locals():\n",
    "    params_pna = count_parameters(model_pna)\n",
    "    print(f\"PNA モデルの総パラメータ数: {params_pna}\")\n",
    "else:\n",
    "    print(\"PNA モデルのインスタンスが見つかりません。\")\n",
    "\n",
    "# GATv2 モデルのパラメータ数を計算\n",
    "if 'model_gatv2' in locals():\n",
    "    params_gatv2 = count_parameters(model_gatv2)\n",
    "    print(f\"GATv2 モデルの総パラメータ数: {params_gatv2}\")\n",
    "else:\n",
    "    print(\"GATv2 モデルのインスタンスが見つかりません。\")\n",
    "    \n",
    "print(f\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a1667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
